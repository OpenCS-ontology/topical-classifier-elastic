{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we present how to query the ES index for paper classification.\n",
    "\n",
    "We assume that the ES is working and responding at the http://localhost:{`PORT`},\n",
    "and an index with name defined in `IDX_NAME` is already build.\n",
    "\n",
    "we ares using article titles and abstract from `data/sample_dataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import IDX_NAME, PORT\n",
    "from source.env_setup.setup import connect_elasticsearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the `IDX_NAME` is defined and print its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    }
   ],
   "source": [
    "with connect_elasticsearch() as es:\n",
    "    mappings = es.indices.get_mapping(index=IDX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ontology_index\": {\n",
      "        \"mappings\": {\n",
      "            \"properties\": {\n",
      "                \"broader\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"closeMatch\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"name\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"prefLabel\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"related\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"type\": {\n",
      "                    \"type\": \"text\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(mappings, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data - sample articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.data.sample_dataset import get_data\n",
    "\n",
    "\n",
    "articles = get_data()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of articles: {len(articles)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': 'Brain Tumor Detection from MRI using Adaptive Thresholding and Histogram based Techniques',\n",
       " 'article_abstract': 'This paper depicts a computerized framework that can distinguish brain tumor and investigate the diverse highlights of the tumor. Brain tumor segmentation means to isolated the unique tumor tissues, for example, active cells, edema and necrotic center from ordinary mind tissues of WM, GM, and CSF. However, manual segmentation in magnetic resonance data is a timeconsuming task. We present a method of automatic tumor segmentation in magnetic resonance images which consists of several steps. The recommended framework is helped by image processing based technique that gives improved precision rate of the cerebrum tumor location along with the computation of tumor measure. In this paper, the location of brain tumor from MRI is recognized utilizing adaptive thresholding with a level set and a morphological procedure with histogram. Automatic brain tumor stage is performed by using ensemble classification. Such phase classifies brain images into tumor and non-tumors using Feed Forwarded Artificial neural network based classifier. For test investigation, continuous MRI images gathered from 200 people are utilized. The rate of fruitful discovery through the proposed procedure is 97.32 percentage accurate.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = articles[0]\n",
    "a0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how querying the index works! \n",
    "\n",
    "A comprehensive guide for the ES queries can be found at: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-multi-match-query.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.es_index.query_index import find_n_best\n",
    "from source.result_saving.result_vocabulary import save_result_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will feed only the tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n",
      "[{'prefLabel': ['Balanced histogram thresholding'], 'score': 14.568794}, {'prefLabel': ['Tumor detection'], 'score': 14.40885}, {'prefLabel': ['Brain tumor segmentation'], 'score': 14.073767}, {'prefLabel': ['Adaptive histogram equalization'], 'score': 12.219425}, {'prefLabel': ['Thresholding'], 'score': 11.079433}, {'prefLabel': ['Mri segmentation'], 'score': 10.983144}, {'prefLabel': ['Histogram'], 'score': 10.140241}, {'prefLabel': ['Blocking techniques'], 'score': 9.020447}, {'prefLabel': ['Recovery techniques'], 'score': 9.020447}, {'prefLabel': ['Visualisation techniques'], 'score': 9.020447}]\n"
     ]
    }
   ],
   "source": [
    "query = {'query': {\n",
    "    \"match\": {\"prefLabel\" : a0['article_title']}\n",
    "    }\n",
    "}\n",
    "\n",
    "with connect_elasticsearch() as es:\n",
    "    res = find_n_best(es, IDX_NAME, query, n=10, label_colname='prefLabel')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try `multi_match`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n",
      "[{'prefLabel': ['Balanced histogram thresholding'], 'score': 43.706383}, {'prefLabel': ['Tumor detection'], 'score': 43.226555}, {'prefLabel': ['Brain tumor segmentation'], 'score': 42.221302}, {'prefLabel': ['Adaptive histogram equalization'], 'score': 36.658276}, {'prefLabel': ['Thresholding'], 'score': 33.2383}, {'prefLabel': ['Mri segmentation'], 'score': 32.949432}, {'prefLabel': ['Histogram'], 'score': 30.420723}, {'prefLabel': ['Blocking techniques'], 'score': 27.061342}, {'prefLabel': ['Recovery techniques'], 'score': 27.061342}, {'prefLabel': ['Visualisation techniques'], 'score': 27.061342}]\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":    a0['article_title'], \n",
    "      \"fields\" : [\"prefLabel^3\", \"related\", \"broader\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "with connect_elasticsearch() as es:\n",
    "    res = find_n_best(es, IDX_NAME, query, n=10, label_colname='prefLabel')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix schema: <http://schema.org/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<http://example.org/result/90a9daef-69c6-413a-ab2f-0762a89b4f5f> a schema:SearchAction ;\n",
      "    schema:endTime \"2023-01-11\"^^xsd:date ;\n",
      "    schema:query \"{'query': {'multi_match': {'query': 'Brain Tumor Detection from MRI using Adaptive Thresholding and Histogram based Techniques', 'fields': ['prefLabel^3', 'related', 'broader']}}}\" ;\n",
      "    schema:result \"[{'prefLabel': ['Balanced histogram thresholding'], 'score': 43.706383}, {'prefLabel': ['Tumor detection'], 'score': 43.226555}, {'prefLabel': ['Brain tumor segmentation'], 'score': 42.221302}, {'prefLabel': ['Adaptive histogram equalization'], 'score': 36.658276}, {'prefLabel': ['Thresholding'], 'score': 33.2383}, {'prefLabel': ['Mri segmentation'], 'score': 32.949432}, {'prefLabel': ['Histogram'], 'score': 30.420723}, {'prefLabel': ['Blocking techniques'], 'score': 27.061342}, {'prefLabel': ['Recovery techniques'], 'score': 27.061342}, {'prefLabel': ['Visualisation techniques'], 'score': 27.061342}]\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(save_result_vocabulary(query, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n",
      "[{'prefLabel': ['Balanced histogram thresholding'], 'score': 99.951416}, {'prefLabel': ['Adaptive histogram equalization'], 'score': 87.61258}, {'prefLabel': ['Histogram matching'], 'score': 66.12162}, {'prefLabel': ['Iterative thresholding'], 'score': 63.40815}, {'prefLabel': ['Thresholding algorithm'], 'score': 63.40815}, {'prefLabel': ['Recurrent Gastrointestinal Stromal Tumor'], 'score': 58.001457}, {'prefLabel': ['Tumor detection'], 'score': 57.6354}, {'prefLabel': ['China brain'], 'score': 57.433777}, {'prefLabel': ['Brain tumor segmentation'], 'score': 56.295067}, {'prefLabel': ['Thresholding'], 'score': 54.596306}]\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":      a0['article_title'],\n",
    "      \"type\":       \"bool_prefix\",\n",
    "      \"fields\":     [\"prefLabel^4\", \"related\", \"broader^2\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "with connect_elasticsearch() as es:\n",
    "    res = find_n_best(es, IDX_NAME, query, n=10, label_colname='prefLabel')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add the abstract as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n",
      "[{'prefLabel': ['Brain tumor segmentation'], 'score': 244.49348}, {'prefLabel': ['Liver tumor segmentation'], 'score': 234.81906}, {'prefLabel': ['Tumor segmentation'], 'score': 207.3719}, {'prefLabel': ['Stromal Neoplasm'], 'score': 195.96886}, {'prefLabel': ['Small Intestinal Gastrointestinal Stromal Tumor'], 'score': 195.96886}, {'prefLabel': ['Malignant Gastrointestinal Stromal Tumor'], 'score': 195.96886}, {'prefLabel': ['Gastric Gastrointestinal Stromal Tumor'], 'score': 195.96886}, {'prefLabel': ['Esophageal GIST'], 'score': 195.96886}, {'prefLabel': ['Recurrent Gastrointestinal Stromal Tumor'], 'score': 195.96886}, {'prefLabel': ['Duodenal submucosal tumor'], 'score': 195.96886}]\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"query\": {\n",
    "    \"dis_max\": {\n",
    "      \"queries\": [\n",
    "        {\n",
    "          \"multi_match\" : {\n",
    "          \"query\":    a0['article_title'], \n",
    "          \"fields\" : [\"prefLabel^3\", \"related\", \"broader\"]\n",
    "    }\n",
    "        },\n",
    "        {\n",
    "          \"multi_match\" : {\n",
    "          \"query\":    a0['article_abstract'], \n",
    "          \"fields\" : [\"prefLabel^2\", \"related\", \"broader^2\"]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "with connect_elasticsearch() as es:\n",
    "    res = find_n_best(es, IDX_NAME, query, n=10, label_colname='prefLabel')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try different parameters in the Elastic Search, e.g., `best_fields` query type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n",
      "[{'prefLabel': ['Brain tumor segmentation'], 'score': 374.2478}, {'prefLabel': ['Tumor segmentation'], 'score': 318.56543}, {'prefLabel': ['Liver tumor segmentation'], 'score': 297.5333}, {'prefLabel': ['Recurrent Gastrointestinal Stromal Tumor'], 'score': 255.27765}, {'prefLabel': ['Tumor detection'], 'score': 254.29216}, {'prefLabel': ['Tumor region'], 'score': 254.29216}, {'prefLabel': ['Nerve tumor'], 'score': 253.00272}, {'prefLabel': ['Stromal tumor'], 'score': 253.00272}, {'prefLabel': ['Is-a'], 'score': 246.47375}, {'prefLabel': ['Duodenal submucosal tumor'], 'score': 242.74872}]\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"query\": {\n",
    "    \"dis_max\": {\n",
    "      \"queries\": [\n",
    "        {\n",
    "          \"multi_match\" : {\n",
    "          \"query\":      a0['article_title'],\n",
    "          \"type\":       \"best_fields\",\n",
    "          \"fields\":     [\"prefLabel^3\", \"related\", \"broader\"],\n",
    "          \"tie_breaker\": 0.3\n",
    "         }\n",
    "        },\n",
    "        {\n",
    "          \"multi_match\" : {\n",
    "          \"query\":      a0['article_abstract'],\n",
    "          \"type\":       \"best_fields\",\n",
    "          \"fields\":     [\"prefLabel^3\", \"related\", \"broader\"],\n",
    "          \"tie_breaker\": 0.3\n",
    "         }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "with connect_elasticsearch() as es:\n",
    "    query_res = find_n_best(es, IDX_NAME, query, n=10, label_colname='prefLabel')\n",
    "\n",
    "print(query_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n",
      "[{'prefLabel': ['Brain tumor segmentation'], 'score': 379.25287}, {'prefLabel': ['Tumor segmentation'], 'score': 323.5705}, {'prefLabel': ['Liver tumor segmentation'], 'score': 321.0152}, {'prefLabel': ['Recurrent Gastrointestinal Stromal Tumor'], 'score': 302.49762}, {'prefLabel': ['Duodenal submucosal tumor'], 'score': 262.3456}, {'prefLabel': ['Gastrointestinal stroma tumor'], 'score': 262.3456}, {'prefLabel': ['Tumor detection'], 'score': 255.1518}, {'prefLabel': ['Tumor region'], 'score': 255.1518}, {'prefLabel': ['Is-a'], 'score': 254.2988}, {'prefLabel': ['Nerve tumor'], 'score': 253.00272}]\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "  \"query\": {\n",
    "    \"dis_max\": {\n",
    "      \"queries\": [\n",
    "        {\n",
    "          \"multi_match\" : {\n",
    "          \"query\":      a0['article_title'],\n",
    "          \"type\":       \"most_fields\",\n",
    "          \"fields\":     [\"prefLabel^3\", \"related\", \"broader\"],\n",
    "          \"tie_breaker\": 0.5\n",
    "         }\n",
    "        },\n",
    "        {\n",
    "          \"multi_match\" : {\n",
    "          \"query\":      a0['article_abstract'],\n",
    "          \"type\":       \"most_fields\",\n",
    "          \"fields\":     [\"prefLabel^3\", \"related\", \"broader\"],\n",
    "          \"tie_breaker\": 0.5\n",
    "         }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "with connect_elasticsearch() as es:\n",
    "    res = find_n_best(es, IDX_NAME, query, n=10, label_colname='prefLabel')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing article from Teams\n",
    "\n",
    "Here we will be using user_query() function which allows user to write and submit his owh query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from source.es_index.query_index import query_es_title, query_es_title_abstract, user_query\n",
    "from source.data.sample_dataset import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1(title):\n",
    "    query = {\n",
    "            \"query\": {\n",
    "                \"multi_match\" : {\n",
    "                    \"query\": title,\n",
    "                    \"fields\" : [\"prefLabel^3\", \"related\", \"broader\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    return query\n",
    "\n",
    "def q2(title, abstract):\n",
    "    query = {\n",
    "            \"query\": {\n",
    "\n",
    "                \"dis_max\": {\n",
    "                    \"queries\": [\n",
    "                        {\n",
    "                            \"multi_match\" : {\n",
    "                                \"query\": title,\n",
    "                                \"type\": \"best_fields\",\n",
    "                                \"fields\": [\"prefLabel^4\", \"related\", \"broader\"],\n",
    "                                \"tie_breaker\": 0.5\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                                \"multi_match\" : {\n",
    "                                \"query\": abstract,\n",
    "                                \"analyzer\" : \"standard\",\n",
    "                                \"type\": \"best_fields\",\n",
    "                                \"fields\": [\"prefLabel^4\", \"related\", \"broader\"],\n",
    "                                \"tie_breaker\": 0.5\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    return query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Background Modelling using a Q-Tree Based Foreground Segmentation\n",
      "Abstract:\n",
      "Background modelling is an empirical part in the procedure of foreground mining of idle and moving objects. The foreground object detection has become a challenging phenomenon due to intermittent objects, intensity variation, image artefact and dynamic background in the video analysis and video surveillance applications. In the video surveillances application, a large amount of data is getting processed by everyday basis. Thus it needs an efficient background modelling technique which could process those larger sets of data which promotes effective foreground detection. In this paper, we presented a renewed background modelling method for foreground segmentation. The main objective of the work is to perform the foreground extraction only in the intended region of interest using proposed Q-Tree algorithm. At most all the present techniques consider their updates to the pixels of the entire frame which may result in inefficient foreground detection with a quick update to slow moving objects. The proposed method contract these defect by extracting the foreground object by controlling the region of interest (the region only where the background subtraction is to be performed) and thereby reducing the false positive and false negative. The extensive experimental results and the evaluation parameters of the proposed approach with the state of art method were compared against the most recent background subtraction approaches. Moreover, we use challenge change detection dataset and the efficiency of our method is analyzed in different environmental conditions (indoor, outdoor) from the CDnet2014 dataset and additional real time videos. The experimental results were satisfactorily verified the strengths and weakness of proposed method against the existing state-of-the-art background modelling methods.\n"
     ]
    }
   ],
   "source": [
    "a3 = get_data()[\"data\"][3]\n",
    "print('Title:\\n' + a3[\"article_title\"])\n",
    "print('Abstract:\\n' + a3[\"article_abstract\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_query(q1(a3[\"article_title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Suicide and the Internet'], 'score': 771.26434},\n",
       " {'prefLabel': ['Confusion of the inverse'], 'score': 768.00586},\n",
       " {'prefLabel': ['Abundances of the elements'], 'score': 748.1553},\n",
       " {'prefLabel': ['Programming in the large and programming in the small'],\n",
       "  'score': 723.5205},\n",
       " {'prefLabel': ['Sociology of the Internet'], 'score': 719.8931},\n",
       " {'prefLabel': ['Outline of the Internet'], 'score': 709.8462},\n",
       " {'prefLabel': ['The Internet'], 'score': 709.3568},\n",
       " {'prefLabel': ['The Blob'], 'score': 701.96844},\n",
       " {'prefLabel': ['The Intersect'], 'score': 701.96844},\n",
       " {'prefLabel': ['The Vanguard Method'], 'score': 701.854}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query(q2(a3[\"article_title\"], a3[\"article_abstract\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Background Modelling using a Q-Tree Based Foreground Segmentation\n",
      "Abstract:\n",
      "Background modelling is an empirical part in the procedure of foreground mining of idle and moving objects. The foreground object detection has become a challenging phenomenon due to intermittent objects, intensity variation, image artefact and dynamic background in the video analysis and video surveillance applications. In the video surveillances application, a large amount of data is getting processed by everyday basis. Thus it needs an efficient background modelling technique which could process those larger sets of data which promotes effective foreground detection. In this paper, we presented a renewed background modelling method for foreground segmentation. The main objective of the work is to perform the foreground extraction only in the intended region of interest using proposed Q-Tree algorithm. At most all the present techniques consider their updates to the pixels of the entire frame which may result in inefficient foreground detection with a quick update to slow moving objects. The proposed method contract these defect by extracting the foreground object by controlling the region of interest (the region only where the background subtraction is to be performed) and thereby reducing the false positive and false negative. The extensive experimental results and the evaluation parameters of the proposed approach with the state of art method were compared against the most recent background subtraction approaches. Moreover, we use challenge change detection dataset and the efficiency of our method is analyzed in different environmental conditions (indoor, outdoor) from the CDnet2014 dataset and additional real time videos. The experimental results were satisfactorily verified the strengths and weakness of proposed method against the existing state-of-the-art background modelling methods.\n"
     ]
    }
   ],
   "source": [
    "a4 = get_data()[\"data\"][3]\n",
    "print('Title:\\n' + a4[\"article_title\"])\n",
    "print('Abstract:\\n' + a4[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Foreground-background'], 'score': 57.03238},\n",
       " {'prefLabel': ['Minimum spanning tree-based segmentation'],\n",
       "  'score': 33.563698},\n",
       " {'prefLabel': ['Tree based'], 'score': 32.92428},\n",
       " {'prefLabel': ['(a,b)-tree'], 'score': 31.327812},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 31.319927},\n",
       " {'prefLabel': ['Graph based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Model based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Tree based regression'], 'score': 27.764553},\n",
       " {'prefLabel': ['Q band'], 'score': 25.940401},\n",
       " {'prefLabel': ['Q-Warrior'], 'score': 25.940401}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query(q1(a4[\"article_title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Suicide and the Internet'], 'score': 771.26434},\n",
       " {'prefLabel': ['Confusion of the inverse'], 'score': 768.00586},\n",
       " {'prefLabel': ['Abundances of the elements'], 'score': 748.1553},\n",
       " {'prefLabel': ['Programming in the large and programming in the small'],\n",
       "  'score': 723.5205},\n",
       " {'prefLabel': ['Sociology of the Internet'], 'score': 719.8931},\n",
       " {'prefLabel': ['Outline of the Internet'], 'score': 709.8462},\n",
       " {'prefLabel': ['The Internet'], 'score': 709.3568},\n",
       " {'prefLabel': ['The Blob'], 'score': 701.96844},\n",
       " {'prefLabel': ['The Intersect'], 'score': 701.96844},\n",
       " {'prefLabel': ['The Vanguard Method'], 'score': 701.854}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query(q2(a4[\"article_title\"], a4[\"article_abstract\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Background Modelling using a Q-Tree Based Foreground Segmentation\n",
      "Abstract:\n",
      "Background modelling is an empirical part in the procedure of foreground mining of idle and moving objects. The foreground object detection has become a challenging phenomenon due to intermittent objects, intensity variation, image artefact and dynamic background in the video analysis and video surveillance applications. In the video surveillances application, a large amount of data is getting processed by everyday basis. Thus it needs an efficient background modelling technique which could process those larger sets of data which promotes effective foreground detection. In this paper, we presented a renewed background modelling method for foreground segmentation. The main objective of the work is to perform the foreground extraction only in the intended region of interest using proposed Q-Tree algorithm. At most all the present techniques consider their updates to the pixels of the entire frame which may result in inefficient foreground detection with a quick update to slow moving objects. The proposed method contract these defect by extracting the foreground object by controlling the region of interest (the region only where the background subtraction is to be performed) and thereby reducing the false positive and false negative. The extensive experimental results and the evaluation parameters of the proposed approach with the state of art method were compared against the most recent background subtraction approaches. Moreover, we use challenge change detection dataset and the efficiency of our method is analyzed in different environmental conditions (indoor, outdoor) from the CDnet2014 dataset and additional real time videos. The experimental results were satisfactorily verified the strengths and weakness of proposed method against the existing state-of-the-art background modelling methods.\n"
     ]
    }
   ],
   "source": [
    "a5 = get_data()[\"data\"][3]\n",
    "print('Title:\\n' + a5[\"article_title\"])\n",
    "print('Abstract:\\n' + a5[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Foreground-background'], 'score': 57.03238},\n",
       " {'prefLabel': ['Minimum spanning tree-based segmentation'],\n",
       "  'score': 33.563698},\n",
       " {'prefLabel': ['Tree based'], 'score': 32.92428},\n",
       " {'prefLabel': ['(a,b)-tree'], 'score': 31.327812},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 31.319927},\n",
       " {'prefLabel': ['Graph based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Model based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Tree based regression'], 'score': 27.764553},\n",
       " {'prefLabel': ['Q band'], 'score': 25.940401},\n",
       " {'prefLabel': ['Q-Warrior'], 'score': 25.940401}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query(q1(a5[\"article_title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Suicide and the Internet'], 'score': 771.26434},\n",
       " {'prefLabel': ['Confusion of the inverse'], 'score': 768.00586},\n",
       " {'prefLabel': ['Abundances of the elements'], 'score': 748.1553},\n",
       " {'prefLabel': ['Programming in the large and programming in the small'],\n",
       "  'score': 723.5205},\n",
       " {'prefLabel': ['Sociology of the Internet'], 'score': 719.8931},\n",
       " {'prefLabel': ['Outline of the Internet'], 'score': 709.8462},\n",
       " {'prefLabel': ['The Internet'], 'score': 709.3568},\n",
       " {'prefLabel': ['The Blob'], 'score': 701.96844},\n",
       " {'prefLabel': ['The Intersect'], 'score': 701.96844},\n",
       " {'prefLabel': ['The Vanguard Method'], 'score': 701.854}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query(q2(a5[\"article_title\"], a5[\"article_abstract\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing final version\n",
    "\n",
    "Testing final version of index and queries on all 6 articles.\n",
    "Here we will be using queries hardcoded in our solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Brain Tumor Detection from MRI using Adaptive Thresholding and Histogram based Techniques\n",
      "Abstract:\n",
      "This paper depicts a computerized framework that can distinguish brain tumor and investigate the diverse highlights of the tumor. Brain tumor segmentation means to isolated the unique tumor tissues, for example, active cells, edema and necrotic center from ordinary mind tissues of WM, GM, and CSF. However, manual segmentation in magnetic resonance data is a timeconsuming task. We present a method of automatic tumor segmentation in magnetic resonance images which consists of several steps. The recommended framework is helped by image processing based technique that gives improved precision rate of the cerebrum tumor location along with the computation of tumor measure. In this paper, the location of brain tumor from MRI is recognized utilizing adaptive thresholding with a level set and a morphological procedure with histogram. Automatic brain tumor stage is performed by using ensemble classification. Such phase classifies brain images into tumor and non-tumors using Feed Forwarded Artificial neural network based classifier. For test investigation, continuous MRI images gathered from 200 people are utilized. The rate of fruitful discovery through the proposed procedure is 97.32 percentage accurate.\n"
     ]
    }
   ],
   "source": [
    "a0 = get_data()[\"data\"][0]\n",
    "print('Title:\\n' + a0[\"article_title\"])\n",
    "print('Abstract:\\n' + a0[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Balanced histogram thresholding'], 'score': 43.706383},\n",
       " {'prefLabel': ['Tumor detection'], 'score': 43.226555},\n",
       " {'prefLabel': ['Brain tumor segmentation'], 'score': 42.221302},\n",
       " {'prefLabel': ['Adaptive histogram equalization'], 'score': 36.658276},\n",
       " {'prefLabel': ['Thresholding'], 'score': 33.2383},\n",
       " {'prefLabel': ['Mri segmentation'], 'score': 32.949432},\n",
       " {'prefLabel': ['Histogram'], 'score': 30.420723},\n",
       " {'prefLabel': ['Blocking techniques'], 'score': 27.061342},\n",
       " {'prefLabel': ['Recovery techniques'], 'score': 27.061342},\n",
       " {'prefLabel': ['Visualisation techniques'], 'score': 27.061342}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title(a0[\"article_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Computerized classification test'], 'score': 89.39671},\n",
       " {'prefLabel': ['Brain tumor segmentation'], 'score': 84.09138},\n",
       " {'prefLabel': ['Balanced histogram thresholding'], 'score': 81.74418},\n",
       " {'prefLabel': ['Level set method'], 'score': 80.56711},\n",
       " {'prefLabel': ['Brain segmentation'], 'score': 79.56774},\n",
       " {'prefLabel': ['Artificial neural network classifier'], 'score': 78.79082},\n",
       " {'prefLabel': ['Artificial brain'], 'score': 77.865166},\n",
       " {'prefLabel': ['Computerized data processing'], 'score': 74.52259},\n",
       " {'prefLabel': ['Neural ensemble'], 'score': 72.62104},\n",
       " {'prefLabel': ['Feed forward artificial neural network'], 'score': 72.58115}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title_abstract(a0[\"article_title\"], a0[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Brain Tumor Detection from MRI using Adaptive Thresholding and Histogram based Techniques\n",
      "Abstract:\n",
      "This paper depicts a computerized framework that can distinguish brain tumor and investigate the diverse highlights of the tumor. Brain tumor segmentation means to isolated the unique tumor tissues, for example, active cells, edema and necrotic center from ordinary mind tissues of WM, GM, and CSF. However, manual segmentation in magnetic resonance data is a timeconsuming task. We present a method of automatic tumor segmentation in magnetic resonance images which consists of several steps. The recommended framework is helped by image processing based technique that gives improved precision rate of the cerebrum tumor location along with the computation of tumor measure. In this paper, the location of brain tumor from MRI is recognized utilizing adaptive thresholding with a level set and a morphological procedure with histogram. Automatic brain tumor stage is performed by using ensemble classification. Such phase classifies brain images into tumor and non-tumors using Feed Forwarded Artificial neural network based classifier. For test investigation, continuous MRI images gathered from 200 people are utilized. The rate of fruitful discovery through the proposed procedure is 97.32 percentage accurate.\n"
     ]
    }
   ],
   "source": [
    "a1 = get_data()[\"data\"][0]\n",
    "print('Title:\\n' + a1[\"article_title\"])\n",
    "print('Abstract:\\n' + a1[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Balanced histogram thresholding'], 'score': 43.706383},\n",
       " {'prefLabel': ['Tumor detection'], 'score': 43.226555},\n",
       " {'prefLabel': ['Brain tumor segmentation'], 'score': 42.221302},\n",
       " {'prefLabel': ['Adaptive histogram equalization'], 'score': 36.658276},\n",
       " {'prefLabel': ['Thresholding'], 'score': 33.2383},\n",
       " {'prefLabel': ['Mri segmentation'], 'score': 32.949432},\n",
       " {'prefLabel': ['Histogram'], 'score': 30.420723},\n",
       " {'prefLabel': ['Blocking techniques'], 'score': 27.061342},\n",
       " {'prefLabel': ['Recovery techniques'], 'score': 27.061342},\n",
       " {'prefLabel': ['Visualisation techniques'], 'score': 27.061342}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title(a1[\"article_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Computerized classification test'], 'score': 89.39671},\n",
       " {'prefLabel': ['Brain tumor segmentation'], 'score': 84.09138},\n",
       " {'prefLabel': ['Balanced histogram thresholding'], 'score': 81.74418},\n",
       " {'prefLabel': ['Level set method'], 'score': 80.56711},\n",
       " {'prefLabel': ['Brain segmentation'], 'score': 79.56774},\n",
       " {'prefLabel': ['Artificial neural network classifier'], 'score': 78.79082},\n",
       " {'prefLabel': ['Artificial brain'], 'score': 77.865166},\n",
       " {'prefLabel': ['Computerized data processing'], 'score': 74.52259},\n",
       " {'prefLabel': ['Neural ensemble'], 'score': 72.62104},\n",
       " {'prefLabel': ['Feed forward artificial neural network'], 'score': 72.58115}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title_abstract(a1[\"article_title\"], a1[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Brain Tumor Detection from MRI using Adaptive Thresholding and Histogram based Techniques\n",
      "Abstract:\n",
      "This paper depicts a computerized framework that can distinguish brain tumor and investigate the diverse highlights of the tumor. Brain tumor segmentation means to isolated the unique tumor tissues, for example, active cells, edema and necrotic center from ordinary mind tissues of WM, GM, and CSF. However, manual segmentation in magnetic resonance data is a timeconsuming task. We present a method of automatic tumor segmentation in magnetic resonance images which consists of several steps. The recommended framework is helped by image processing based technique that gives improved precision rate of the cerebrum tumor location along with the computation of tumor measure. In this paper, the location of brain tumor from MRI is recognized utilizing adaptive thresholding with a level set and a morphological procedure with histogram. Automatic brain tumor stage is performed by using ensemble classification. Such phase classifies brain images into tumor and non-tumors using Feed Forwarded Artificial neural network based classifier. For test investigation, continuous MRI images gathered from 200 people are utilized. The rate of fruitful discovery through the proposed procedure is 97.32 percentage accurate.\n"
     ]
    }
   ],
   "source": [
    "a2 = get_data()[\"data\"][0]\n",
    "print('Title:\\n' + a2[\"article_title\"])\n",
    "print('Abstract:\\n' + a2[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Balanced histogram thresholding'], 'score': 43.706383},\n",
       " {'prefLabel': ['Tumor detection'], 'score': 43.226555},\n",
       " {'prefLabel': ['Brain tumor segmentation'], 'score': 42.221302},\n",
       " {'prefLabel': ['Adaptive histogram equalization'], 'score': 36.658276},\n",
       " {'prefLabel': ['Thresholding'], 'score': 33.2383},\n",
       " {'prefLabel': ['Mri segmentation'], 'score': 32.949432},\n",
       " {'prefLabel': ['Histogram'], 'score': 30.420723},\n",
       " {'prefLabel': ['Blocking techniques'], 'score': 27.061342},\n",
       " {'prefLabel': ['Recovery techniques'], 'score': 27.061342},\n",
       " {'prefLabel': ['Visualisation techniques'], 'score': 27.061342}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title(a2[\"article_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Computerized classification test'], 'score': 89.39671},\n",
       " {'prefLabel': ['Brain tumor segmentation'], 'score': 84.09138},\n",
       " {'prefLabel': ['Balanced histogram thresholding'], 'score': 81.74418},\n",
       " {'prefLabel': ['Level set method'], 'score': 80.56711},\n",
       " {'prefLabel': ['Brain segmentation'], 'score': 79.56774},\n",
       " {'prefLabel': ['Artificial neural network classifier'], 'score': 78.79082},\n",
       " {'prefLabel': ['Artificial brain'], 'score': 77.865166},\n",
       " {'prefLabel': ['Computerized data processing'], 'score': 74.52259},\n",
       " {'prefLabel': ['Neural ensemble'], 'score': 72.62104},\n",
       " {'prefLabel': ['Feed forward artificial neural network'], 'score': 72.58115}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title_abstract(a2[\"article_title\"], a2[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Background Modelling using a Q-Tree Based Foreground Segmentation\n",
      "Abstract:\n",
      "Background modelling is an empirical part in the procedure of foreground mining of idle and moving objects. The foreground object detection has become a challenging phenomenon due to intermittent objects, intensity variation, image artefact and dynamic background in the video analysis and video surveillance applications. In the video surveillances application, a large amount of data is getting processed by everyday basis. Thus it needs an efficient background modelling technique which could process those larger sets of data which promotes effective foreground detection. In this paper, we presented a renewed background modelling method for foreground segmentation. The main objective of the work is to perform the foreground extraction only in the intended region of interest using proposed Q-Tree algorithm. At most all the present techniques consider their updates to the pixels of the entire frame which may result in inefficient foreground detection with a quick update to slow moving objects. The proposed method contract these defect by extracting the foreground object by controlling the region of interest (the region only where the background subtraction is to be performed) and thereby reducing the false positive and false negative. The extensive experimental results and the evaluation parameters of the proposed approach with the state of art method were compared against the most recent background subtraction approaches. Moreover, we use challenge change detection dataset and the efficiency of our method is analyzed in different environmental conditions (indoor, outdoor) from the CDnet2014 dataset and additional real time videos. The experimental results were satisfactorily verified the strengths and weakness of proposed method against the existing state-of-the-art background modelling methods.\n"
     ]
    }
   ],
   "source": [
    "a3 = get_data()[\"data\"][3]\n",
    "print('Title:\\n' + a3[\"article_title\"])\n",
    "print('Abstract:\\n' + a3[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Foreground-background'], 'score': 57.03238},\n",
       " {'prefLabel': ['Minimum spanning tree-based segmentation'],\n",
       "  'score': 33.563698},\n",
       " {'prefLabel': ['Tree based'], 'score': 32.92428},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 31.319927},\n",
       " {'prefLabel': ['Graph based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Model based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Tree based regression'], 'score': 27.764553},\n",
       " {'prefLabel': ['Segmentation-based object categorization'],\n",
       "  'score': 25.757818},\n",
       " {'prefLabel': ['Background process'], 'score': 25.712452},\n",
       " {'prefLabel': ['Background image'], 'score': 25.712452}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title(a3[\"article_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Background subtraction'], 'score': 79.02078},\n",
       " {'prefLabel': ['Positive and negative sets'], 'score': 78.84243},\n",
       " {'prefLabel': ['Foreground-background'], 'score': 77.15093},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 76.79746},\n",
       " {'prefLabel': ['False-positive test result'], 'score': 74.046555},\n",
       " {'prefLabel': ['False-negative test result'], 'score': 74.046555},\n",
       " {'prefLabel': ['Verified procedure'], 'score': 72.7784},\n",
       " {'prefLabel': ['Image subtraction'], 'score': 72.40406},\n",
       " {'prefLabel': ['Object detection image segmentation'], 'score': 70.34129},\n",
       " {'prefLabel': ['Real time data mining'], 'score': 69.0508}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title_abstract(a3[\"article_title\"], a3[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Background Modelling using a Q-Tree Based Foreground Segmentation\n",
      "Abstract:\n",
      "Background modelling is an empirical part in the procedure of foreground mining of idle and moving objects. The foreground object detection has become a challenging phenomenon due to intermittent objects, intensity variation, image artefact and dynamic background in the video analysis and video surveillance applications. In the video surveillances application, a large amount of data is getting processed by everyday basis. Thus it needs an efficient background modelling technique which could process those larger sets of data which promotes effective foreground detection. In this paper, we presented a renewed background modelling method for foreground segmentation. The main objective of the work is to perform the foreground extraction only in the intended region of interest using proposed Q-Tree algorithm. At most all the present techniques consider their updates to the pixels of the entire frame which may result in inefficient foreground detection with a quick update to slow moving objects. The proposed method contract these defect by extracting the foreground object by controlling the region of interest (the region only where the background subtraction is to be performed) and thereby reducing the false positive and false negative. The extensive experimental results and the evaluation parameters of the proposed approach with the state of art method were compared against the most recent background subtraction approaches. Moreover, we use challenge change detection dataset and the efficiency of our method is analyzed in different environmental conditions (indoor, outdoor) from the CDnet2014 dataset and additional real time videos. The experimental results were satisfactorily verified the strengths and weakness of proposed method against the existing state-of-the-art background modelling methods.\n"
     ]
    }
   ],
   "source": [
    "a4 = get_data()[\"data\"][3]\n",
    "print('Title:\\n' + a4[\"article_title\"])\n",
    "print('Abstract:\\n' + a4[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Foreground-background'], 'score': 57.03238},\n",
       " {'prefLabel': ['Minimum spanning tree-based segmentation'],\n",
       "  'score': 33.563698},\n",
       " {'prefLabel': ['Tree based'], 'score': 32.92428},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 31.319927},\n",
       " {'prefLabel': ['Graph based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Model based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Tree based regression'], 'score': 27.764553},\n",
       " {'prefLabel': ['Segmentation-based object categorization'],\n",
       "  'score': 25.757818},\n",
       " {'prefLabel': ['Background process'], 'score': 25.712452},\n",
       " {'prefLabel': ['Background image'], 'score': 25.712452}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title(a4[\"article_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Background subtraction'], 'score': 79.02078},\n",
       " {'prefLabel': ['Positive and negative sets'], 'score': 78.84243},\n",
       " {'prefLabel': ['Foreground-background'], 'score': 77.15093},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 76.79746},\n",
       " {'prefLabel': ['False-positive test result'], 'score': 74.046555},\n",
       " {'prefLabel': ['False-negative test result'], 'score': 74.046555},\n",
       " {'prefLabel': ['Verified procedure'], 'score': 72.7784},\n",
       " {'prefLabel': ['Image subtraction'], 'score': 72.40406},\n",
       " {'prefLabel': ['Object detection image segmentation'], 'score': 70.34129},\n",
       " {'prefLabel': ['Real time data mining'], 'score': 69.0508}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title_abstract(a4[\"article_title\"], a4[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Background Modelling using a Q-Tree Based Foreground Segmentation\n",
      "Abstract:\n",
      "Background modelling is an empirical part in the procedure of foreground mining of idle and moving objects. The foreground object detection has become a challenging phenomenon due to intermittent objects, intensity variation, image artefact and dynamic background in the video analysis and video surveillance applications. In the video surveillances application, a large amount of data is getting processed by everyday basis. Thus it needs an efficient background modelling technique which could process those larger sets of data which promotes effective foreground detection. In this paper, we presented a renewed background modelling method for foreground segmentation. The main objective of the work is to perform the foreground extraction only in the intended region of interest using proposed Q-Tree algorithm. At most all the present techniques consider their updates to the pixels of the entire frame which may result in inefficient foreground detection with a quick update to slow moving objects. The proposed method contract these defect by extracting the foreground object by controlling the region of interest (the region only where the background subtraction is to be performed) and thereby reducing the false positive and false negative. The extensive experimental results and the evaluation parameters of the proposed approach with the state of art method were compared against the most recent background subtraction approaches. Moreover, we use challenge change detection dataset and the efficiency of our method is analyzed in different environmental conditions (indoor, outdoor) from the CDnet2014 dataset and additional real time videos. The experimental results were satisfactorily verified the strengths and weakness of proposed method against the existing state-of-the-art background modelling methods.\n"
     ]
    }
   ],
   "source": [
    "a5 = get_data()[\"data\"][3]\n",
    "print('Title:\\n' + a5[\"article_title\"])\n",
    "print('Abstract:\\n' + a5[\"article_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Foreground-background'], 'score': 57.03238},\n",
       " {'prefLabel': ['Minimum spanning tree-based segmentation'],\n",
       "  'score': 33.563698},\n",
       " {'prefLabel': ['Tree based'], 'score': 32.92428},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 31.319927},\n",
       " {'prefLabel': ['Graph based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Model based segmentation'], 'score': 29.79445},\n",
       " {'prefLabel': ['Tree based regression'], 'score': 27.764553},\n",
       " {'prefLabel': ['Segmentation-based object categorization'],\n",
       "  'score': 25.757818},\n",
       " {'prefLabel': ['Background process'], 'score': 25.712452},\n",
       " {'prefLabel': ['Background image'], 'score': 25.712452}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title(a4[\"article_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay Connected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prefLabel': ['Background subtraction'], 'score': 79.02078},\n",
       " {'prefLabel': ['Positive and negative sets'], 'score': 78.84243},\n",
       " {'prefLabel': ['Foreground-background'], 'score': 77.15093},\n",
       " {'prefLabel': ['Foreground detection'], 'score': 76.79746},\n",
       " {'prefLabel': ['False-positive test result'], 'score': 74.046555},\n",
       " {'prefLabel': ['False-negative test result'], 'score': 74.046555},\n",
       " {'prefLabel': ['Verified procedure'], 'score': 72.7784},\n",
       " {'prefLabel': ['Image subtraction'], 'score': 72.40406},\n",
       " {'prefLabel': ['Object detection image segmentation'], 'score': 70.34129},\n",
       " {'prefLabel': ['Real time data mining'], 'score': 69.0508}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_es_title_abstract(a5[\"article_title\"], a5[\"article_abstract\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb909539cb839e11f775ecf6d9728e5f3e2dc70caaa179a79ead8efd4e3c2239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
